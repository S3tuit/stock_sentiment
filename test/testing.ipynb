{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from pymongo import MongoClient\n",
    "\n",
    "TICKETS = {'RIOT': 1, 'ACMR': 1, 'OXY': 0, 'AAPL': 1, 'JNJ': 0, 'WMT': 0, 'PG': 0, 'PATH': 0, 'BYND': 1, 'JPM':0}\n",
    "\n",
    "tickets = list(TICKETS.keys())\n",
    "\n",
    "\n",
    "def get_latest_articles(tickets, source):\n",
    "    client = MongoClient(\"mongodb://peppa:peppa@localhost:27017\")\n",
    "    db = client.stock_test\n",
    "    articles_collection = db.articles_test\n",
    "    cache_collection = db.articles_cache\n",
    "\n",
    "    # MongoDB aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"source\": source}},  # Match the source\n",
    "        {\"$sort\": {\"timestamp\": -1}},  # Sort by timestamp in descending order (latest first)\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$ticket\",  # Group by ticket\n",
    "            \"ticket\": {\"$first\": \"$ticket\"},\n",
    "            \"title\": {\"$first\": \"$title\"},  # Get the title of the latest article\n",
    "            \"source\": {\"$first\": \"$source\"}\n",
    "        }},\n",
    "        {\"$project\": {\"_id\": 0, \"ticket\": 1, \"title\": 1, \"source\": 1}}  # Exclude _id field\n",
    "    ]\n",
    "\n",
    "    latest_articles = list(articles_collection.aggregate(pipeline))\n",
    "\n",
    "    upsert_articles(article_entities=latest_articles, collection=cache_collection)\n",
    "    \n",
    "    return latest_articles\n",
    "\n",
    "def upsert_articles(article_entities, collection):\n",
    "    # Perform upsert operations on articles_cache\n",
    "    for article in article_entities:\n",
    "        collection.update_one(\n",
    "            {\"ticket\": article[\"ticket\"], \"source\": article[\"source\"]},  # Match criteria\n",
    "            {\"$set\": {\n",
    "                \"title\": article[\"title\"]\n",
    "            }},\n",
    "            upsert=True  # Upsert flag to insert if no match is found\n",
    "        )\n",
    "\n",
    "    return article_entities  # Optionally return the upserted articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_articles = get_latest_articles(tickets=tickets, source='seeking_alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ticket': 'riot',\n",
       " 'title': 'Riot Platforms, MARA, CleanSpark, Cipher land Outperform rates from Macquarie',\n",
       " 'source': 'seeking_alpha',\n",
       " 'timestamp': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_articles[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_kafka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
